
Since the first computer program written by Ada Lovelace in the middle of the 19th century, variability allows one to reuse pieces of code in different contexts. For instance, variations in the input of a program triggers different behaviours and produces different outputs. 
In the same way, procedural abstraction allows to reuse procedures and functions in different contexts. This goes even further with the development of object oriented and other programming paradigms. In 1968, during the first NATO software engineering conference \cite{Naur1969}, Malcolm Douglas McIlroy, one of the pioneer of component-based software engineering, gave a talk entitled ``Mass Produced Software Components'' \cite{Mcilroy1969} where he advocates the development of component families: ``\textit{Software components (routines), to be widely applicable to different machines and users, should be available in families arranged according to precision, robustness, generality and timespace performance.}''
Almost fifty years later, lot of systems are \emph{variability intensive}. They are configurable or use a plugin-based architecture to be customizable in order to adapt to specific needs without requiring further development.

\glsreset{SPL}

Those ideas are not new. In the early 20th century, Henry Ford achieved mass production of the \textit{Model T} car by standardizing its components (to make then interchangeable) and reorganising the manufacturing process around an assembly line with dedicated tools and equipments, to allow unskilled workers to contribute to the building process.
For years, the manufacturing industry achieved eco\-no\-mies of scope based on this idea that a product of a certain family (\eg cars) may be built by systematically reusing assets, with some of them common to all family members (\eg wheels or bodywork) and others only shared by a subset of the family (\eg automatic transmission, manual transmission, or leather seats). The \emph{\gls{SPL}} paradigm \cite{Pohl2005} applies this idea to software products. In \gls{SPL} engineering, we usually associate assets with so-called \emph{features} and we regard a product as a combination of features. Features can be designed and specified using various modelling languages, while the set of legal combinations of features (that is, the set of valid products) is captured by a \acrfull{FM} \cite{Kang1990}.

As in single-system development, the engineer has to improve confidence in the different products of an \gls{SPL} by using appropriate quality assurance techniques. Two popular approaches are \emph{model checking} and \emph{testing}. Model checking~\cite{Clarke1999} performs systematic analyses on behavioural models in order to assess the satisfaction of the intended temporal and qualitative requirements and properties. As a complement to model-checking, testing \cite{Mathur2008} determines whether or not actual executions of the system behave as expected.

%----------------------------------------
\section{Context and problem statement}
%----------------------------------------

In this \gls{SPL} context, the large number of possible combinations of features makes product-based analysis (\ie testing or model checking every possible software product) intractable. 
For instance, the Linux kernel for x86 architectures (v.2.6.28.6) has 5,426 features (of which 4,744 may be selected by the end users) \cite{She2011,Apel2013}, which gives billions of possible products. 
As a point of comparison, an \gls{SPL} with 33 independent and optional features is enough to build a unique product for every human on earth. An SPL with 320 independent and optional features has more products than the estimated number of atoms in the universe. 
Even small product lines requires a lot of effort to achieve a complete product-based analysis: in their recent work, Halin \etal \cite{Halin2017,Halin2017b} report their effort to perform a complete product-based testing of JHipster, an open-source generator for Web applications with 48 features. It took 8 person/month to set up the testing infrastructure, 5.2 Terrabytes diskspace, and 4,376 hours (around 182 days) computation time to test all 26,256 products. 
Considering development practices, like continuous integration and delivery, fast release, \etc, this brute force approach cannot be applied in many cases. 

To cope with the large number of products in a SPL, the model checking community devised, over the years, several efficient \emph{family-based} analysis \cite{Thum2014}: \ie analysis performed on the reusable assets of the SPL (called domain artefacts) instead of products, and using the \gls{feature model} to consider valid combinations of those assets during the analysis. For instance, model checking of SPL specifications, expressed using a transition system with variability information \cite{Classen2013b,Fischbein2006}, allows to ensure that a given property holds for every product of the product line. Many other formal approaches, meant to detect undesired feature interactions (\ie undesired behaviour emerging when two or more features are involved in the same product), have been developed \cite{Calder2003,Nhlabatsi2008} and successfully used to validate abstract models of \glspl{SPL} \cite{Heymans2012,Shaker2014b,Zave1993}. Scalable application of formal methods to source code remains an open problem \cite{Apel2013}.

During the last decade, the research community has showed a growing interest in SPL testing \cite{Heradio2015}. 
SPL testing aims at validating an SPL by executing a \textit{good enough} finite set of test cases (on a set of products). 
As testing all the products of a product line is infeasible, the main challenge is to select a representative \emph{subset of all the products} and execute test cases over this subset. First work on behavioural SPL testing are mainly focused on how to reuse test cases from one product to another (by deriving them automatically from domain artefacts for instance) \cite{Heradio2015,Oster2011}. Despite those advances, the development of practical SPL testing techniques is still in an immature stage \cite{Engstrom2011,Machado2014}. In particular, one question remains: 

\begin{quote}
How to \emph{select} a representative subset of \emph{products} and with which \emph{test cases}?
\end{quote}

Recent work tackles this problem by using \emph{sampling} over the feature model. \Gls{CIT} techniques have been adapted to the SPL context \cite{Cohen2008,Perrouin2011,PerezLamancha2010,Hervieu2011,Johansen2012b,Lopez-Herrejon2013} to ensure that combinations of features are present in at least one product to test: \eg pairwise sampling ensures that all valid pairs of features are present in at least one product. Other approaches use a dissimilarity heuristic to sample, based on a time and testing budget, a set of products as dissimilar as possible in terms of features \cite{Henard2014a,Al-Hajjaji2016}. Or use other information from the feature model (\eg features cost) \cite{Ensan2012,Henard2013a,Sayyad2013a,Sanchez2013}.
The large majority of \gls{CIT} approaches are model-based and use the feature model as main artefact to perform a product sampling, answering only to the former part of the question.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Contributions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\glsreset{FTS} \glsreset{AbsCon} \glsreset{QTaste} \glsreset{VIBeS}

In this thesis, we consider the \emph{behaviour} of the SPL in \emph{addition} of the feature model as the main driver of the test selection process. We present a \emph{model-based} testing framework to select test cases and products, based on a \emph{behavioural} model of the SPL. We rely on the advances made by the model checking community to describe SPL behaviour in a \gls{FTS} \cite{Classen2013b}, a compact formalism used to represent the behaviour as a transition system where transitions are tagged with feature expressions specifying which products may fire the transition. 
As for other SPL approaches \cite{Nguyen2014,Struber2015,Kim2013a}, \glspl{FTS} are executed in a family-based fashion: \ie executions of parts common to several products are factorized, thanks to a variability aware execution engine.
We define the notion of \emph{\gls{abstract test case}} as a sequence of actions to perform on the system and show how to, based on a set of abstract test cases, we sample relevant products. We devise several abstract test case selection strategies (with the corresponding algorithms) and define a compact formalism to improve mutation analysis. The different selection strategies and mutation analysis are implemented in our \gls{VIBeS} framework, and evaluated on several case studies, some of them part of the research literature and some of them specific to this thesis. Finally, we show how the abstract test cases are concretized using an \gls{AbsCon}, a plugin for the \gls{QTaste}. 

%To achieve a behavioural model-based test case selection, we propose a testing framework which elements constitute  the contribution of this thesis.

\paragraph{Abstract test case over an FTS:}
%--------------------------------------------

Contrary to existing sampling based approaches, we do not seek to cover combinations of features but rather the behaviour of the product line.
In this thesis, we adopt a model-based approach to select test cases from a \gls{FTS}, representing this behaviour. Our first contribution is the definition of \emph{\gls{abstract test case}} and how it can be used to \emph{sample relevant products} to test.

\paragraph{Abstract test case selection based on the FTS structure:}
%--------------------------------------------------------------------

Our first abstract test case selection strategy is based on the structure of the \gls{FTS}. We redefine the \emph{states}, \emph{actions}, \emph{transitions}, \emph{transition-pairs}, and \emph{paths} \emph{coverage} for FTSs and provide a first all-states \emph{selection algorithm}. We also define the notions of \emph{abstract test case} and \emph{test suite} \emph{minimality}. Finally, we provide a \emph{prioritization} strategy to order products to test according to the test cases they can execute. 


\paragraph{Abstract test case selection based on a dissimilarity heuristic:}
%--------------------------------------------------------------------

The second abstract test case selection strategy uses a dissimilarity heuristic, which aims to maximise the fault detection rate by increasing diversity among abstract test cases \cite{Cartaxo2011,Hemmati2013}. 
In this thesis, we present a \emph{configurable dissimilar abstract test case selection algorithm} that uses random abstract test case selection and a \emph{distance} function to guide the selection. The distance is defined on the actions of the abstract test cases that may optionally be combined, using a binary operator, with a distance (the Jaccard index product dissimilarity) defined over the set of products able to execute those abstract test cases. To characterise the actions used in an abstract test case, we consider set-based distances (Hamming, Jaccard, dice, and anti-dice distances) and a sequence-based distance (Levenshtein or edit distance).


\paragraph{Abstract test case selection based on usages:}
%--------------------------------------------------------------------

The last abstract test case selection strategy described in this thesis is based on the usage of the product line.  This work is inspired from statistical testing \cite{Whittaker1994}, which selects abstract test cases from a \gls{usage model} represented by a \gls{DTMC}. The idea is to \emph{select} abstract test cases from the usage model (and the FTS, since the usage model is agnostic of the variability constraints of the SPL), based on their \emph{probability to happen}. The set of selected abstract test cases is also used to \emph{prioritize products} to test, based on their behavioural usages.


\paragraph{Compact mutants model:}
%--------------------------------------------

\glsreset{FMM}

Mutation analysis is a popular technique to assess the adequacy of a test suite. The idea is to inject artificial faults (using mutation operators) in the system under test and to execute the test suite against each one of the faulty systems (\ie mutants). This analysis may take time for a large number of mutants. In this thesis, we propose a product line approach of model-based mutation testing. Since mutants are small variations of the system, mutants are seen as members (\ie products) of a \emph{mutants family} (\ie a product line of mutants). We define a compact mutants model using variability mechanisms: the \gls{FMM}. We provide \emph{algorithms} and \emph{mutation operators} to build a \gls{FMM} and describe its mechanism allowing to \emph{execute} a test case on all mutants in one single execution. Finally, we show how \gls{FMM} is used as a \emph{compact representation} for first and higher orders mutants.


\paragraph{Equivalent mutant detection using automata language equivalence:}
%---------------------------------------------------------------------------

\glsreset{ALE} \glsreset{EMP} \glsreset{RS} \glsreset{BS}

Equivalent mutants are mutants whose behaviour is identical to the original system. As they cannot be distinguished by any test case, they do not bring new value to the analysis. This thesis enhance the model-based mutation testing research field by addressing one of its main challenge: the \gls{EMP}. We express \gls{EMP} as a classical problem in automata theory, \gls{ALE}, and see how \emph{language equivalence} may be used to \emph{detect equivalent mutants} in strong and weak mutation scenarios. As baseline, we also provide two \emph{randomized simulation} techniques to detect equivalent mutants: \gls{RS} and \gls{BS}.


\paragraph{VIBeS implementation:}
%--------------------------------------------

\gls{VIBeS} is implemented in Java as an open-source multi-module Maven project. It allows one to \emph{define} \glspl{FTS} and perform the \emph{various testing activities} described in this thesis using a front end \gls{API}. The source code is publicly available on GitHub (\url{https://github.com/xdevroey/vibes}) and the Maven artefacts have been deployed in the Maven central repository, making them available to other Maven users.


\paragraph{SPL case studies:}
%--------------------------------------------

We manually defined one new case study: the \emph{card payment terminal SPL}, based on standard documentation \cite{EMVCo2011}. We also semi-automatically reverse engineer five models of two Web applications, based on several months of log entries: one model for \emph{Claroline}, a course management system, and four models for \emph{WordPress}, an open-source \gls{CMS}. The feature models, \glspl{FTS}, and \glspl{usage model} are publicly available online (\url{https://projects.info.unamur.be/vibes/}) and may be used or adapted by the research community.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Structure of the thesis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The remainder of this manuscript is divided as follows: Part \ref{part:background} gives the background used in the following parts. Chapter \ref{chap:vis} introduces software product lines, feature models, and featured transition systems. Chapter\ref{chap:vis-testing} presents the state of the art in product line testing.
%
Part \ref{part:framework} contains the main contributions of this thesis. It presents our model-driven behavioural testing framework in Chapter \ref{chap:frameworkdescription} and the case studies used to illustrate and assess the different approaches in Chapter \ref{chap:casestudies}. Chapter \ref{chap:coverage} describes the different abstract test case selection techniques: structural coverage driven, dissimilarity driven, and usage-base driven. Chapter \ref{chap:mutation} presents mutation analysis using \glspl{FMM} and how to detect equivalent mutants using automata language equivalence and random simulation. Finally, chapter \ref{chap:assessment} presents the empirical assessments of the elements from Chapters \ref{chap:coverage} and \ref{chap:mutation}.
%
Implementations are described in Part \ref{part:implem}. Chapter \ref{chap:vibes} presents \gls{VIBeS} and Chapter \ref{chap:concretization} shows how abstract test cases may be concretized using \gls{AbsCon}.
%
Finally, Part \ref{part:postface} and Chapter \ref{chap:conclusion} conclude this thesis and present research perspectives.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Publications}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The content of this thesis is based upon, reuses, and extends the following peer-reviewed publications of the author:

%----------------------------
\subsection{Journal}
%----------------------------

\begin{itemize}
\item[\cite{Devroey2015a}] \bibentry{Devroey2015a}
\end{itemize}

%----------------------------
\subsection{Conferences}
%----------------------------

\begin{itemize}
\item[\cite{Devroey2012}] \bibentry{Devroey2012}
\item[\cite{Devroey2014f}] \bibentry{Devroey2014f}
\item[\cite{Devroey2014e}] \bibentry{Devroey2014e}
\item[\cite{Devroey2016a}] \bibentry{Devroey2016a}
\item[\cite{Legay2017}] \bibentry{Legay2017} (invited paper)
\item[\cite{Devroey2017}] \bibentry{Devroey2017}
\end{itemize}


%----------------------------
\subsection{Workshops}
%----------------------------

\begin{itemize}
\item[\cite{Devroey2014}] \bibentry{Devroey2014}
\item[\cite{Devroey2014c}] \bibentry{Devroey2014c}
\item[\cite{Devroey2015b}] \bibentry{Devroey2015b}
\item[\cite{Devroey2015c}] \bibentry{Devroey2015c}
\item[\cite{Devroey2016}] \bibentry{Devroey2016}
\item[\cite{Halin2017}] \bibentry{Halin2017}
\end{itemize}

